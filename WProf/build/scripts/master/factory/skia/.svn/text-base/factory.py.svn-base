# Copyright (c) 2012 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""Utility class to build the Skia master BuildFactory's.

Based on gclient_factory.py and adds Skia-specific steps."""

import ntpath
import posixpath

from buildbot.process.properties import WithProperties

from master.factory import gclient_factory
from master.factory.skia import commands as skia_commands

import config

AUTOGEN_SVN_BASEURL = 'https://skia-autogen.googlecode.com/svn'
BENCH_REPEAT_COUNT = 20
BENCH_GRAPH_NUM_REVISIONS = 150
BENCH_GRAPH_X = 1024
BENCH_GRAPH_Y = 768

# TODO(epoger): My intent is to make the build steps identical on all platforms
# and thus remove the need for the whole target_platform parameter.
# For now, these must match the target_platform values used in
# third_party/chromium_buildbot/scripts/master/factory/gclient_factory.py ,
# because we pass these values into GClientFactory.__init__() .
TARGET_PLATFORM_LINUX = 'linux'
TARGET_PLATFORM_MAC = 'mac'
TARGET_PLATFORM_WIN32 = 'win32'

class SkiaFactory(gclient_factory.GClientFactory):
  """Encapsulates data and methods common to the Skia master.cfg files."""

  def __init__(self, do_upload_results=False,
               build_subdir='trunk', other_subdirs=None,
               target_platform=None, configuration='Debug',
               default_timeout=600,
               environment_variables=None, gm_image_subdir=None,
               perf_output_basedir=None, builder_name=None):
    """Instantiates a SkiaFactory as appropriate for this target_platform.

    do_upload_results: whether we should upload bench/gm results
    build_subdir: subdirectory to check out and then build within
    other_subdirs: list of other subdirectories to also check out (or None)
    target_platform: a string such as TARGET_PLATFORM_LINUX
    configuration: 'Debug' or 'Release'
    default_timeout: default timeout for each command, in seconds
    environment_variables: dictionary of environment variables that should
        be passed to all commands
    gm_image_subdir: directory containing images for comparison against results
        of gm tool
    perf_output_basedir: path to directory under which to store performance
        data, or None if we don't want to store performance data
    builder_name: name of the builder associated with this factory
    """
    # Create gclient solutions corresponding to the main build_subdir
    # and other directories we also wish to check out.
    solutions = [gclient_factory.GClientSolution(
        svn_url=config.Master.skia_url + build_subdir, name=build_subdir)]
    if other_subdirs:
      for other_subdir in other_subdirs:
        solutions.append(gclient_factory.GClientSolution(
            svn_url=config.Master.skia_url + other_subdir, name=other_subdir))
    gclient_factory.GClientFactory.__init__(
        self, build_dir='', solutions=solutions,
        target_platform=target_platform)

    self._do_upload_results = do_upload_results
    self._configuration = configuration
    self._factory = self.BaseFactory(factory_properties=None)
    self._gm_image_subdir = gm_image_subdir
    self._builder_name = builder_name
    self._target_platform = target_platform

    # Set _default_clobber based on config.Master
    self._default_clobber = getattr(config.Master, 'default_clobber', False)

    # Platform-specific stuff.
    if target_platform == TARGET_PLATFORM_WIN32:
      self.TargetPathJoin = ntpath.join
      self._make_flags = 'BUILDTYPE=%s' % self._configuration
    else:
      self.TargetPathJoin = posixpath.join
      self._make_flags = '--jobs --max-load=4.0 BUILDTYPE=%s' % (
          self._configuration)

    # Figure out where we are going to store performance output.
    if perf_output_basedir:
      self._perf_data_dir = self.TargetPathJoin(
          perf_output_basedir, builder_name, 'data')
      self._perf_graphs_dir = self.TargetPathJoin(
          perf_output_basedir, builder_name, 'graphs')
    else:
      self._perf_data_dir = None
      self._perf_graphs_dir = None

    # Figure out where we are going to store images generated by GM.
    self._gm_actual_dir = self.TargetPathJoin('..', '..', 'gm', 'actual')
    self._gm_actual_svn_baseurl = '%s/%s' % (AUTOGEN_SVN_BASEURL, 'gm-actual')
    self._autogen_svn_username_file = '.autogen_svn_username'
    self._autogen_svn_password_file = '.autogen_svn_password'

    # Get an implementation of SkiaCommands as appropriate for
    # this target_platform.
    workdir = self.TargetPathJoin('build', build_subdir)
    self._skia_cmd_obj = skia_commands.SkiaCommands(
        target_platform=target_platform, factory=self._factory,
        configuration=configuration, workdir=workdir,
        target_arch=None, default_timeout=default_timeout,
        environment_variables=environment_variables)

  def Build(self, clobber=None):
    """Build and return the complete BuildFactory.

    clobber: boolean indicating whether we should clean before building
    """
    if clobber is None:
      clobber = self._default_clobber
    if clobber:
      self._skia_cmd_obj.AddClean()

    # Do all the build steps first, so we will find out about build breakages
    # as soon as possible.
    self._skia_cmd_obj.AddRun(
        run_command='make core %s' % self._make_flags,
        description='BuildCore')
    self._skia_cmd_obj.AddRun(
        run_command='make tests %s' % self._make_flags,
        description='BuildTests')
    self._skia_cmd_obj.AddRun(
        run_command='make gm %s' % self._make_flags,
        description='BuildGM')
    self._skia_cmd_obj.AddRun(
        run_command='make bench %s' % self._make_flags,
        description='BuildBench')
    self._skia_cmd_obj.AddRun(
        run_command='make all %s' % self._make_flags,
        description='BuildAllOtherTargets')

    self._skia_cmd_obj.AddRun(
        run_command=self.TargetPathJoin('out', self._configuration, 'tests'),
        description='RunTests')

    # Run the "GM" tool, comparing actual results against the baselines in
    # _gm_image_subdir.
    path_to_gm = self.TargetPathJoin('out', self._configuration, 'gm')
    path_to_image_subdir = self.TargetPathJoin('gm', self._gm_image_subdir)
    self._skia_cmd_obj.AddRun(
        run_command='%s -r %s' % (path_to_gm, path_to_image_subdir),
        description='RunGM')

    # Rerun GM, uploading actual results to the skia-autogen SVN repository
    # to aid in rebaselining.
    #
    # TODO: bungeman suggests: if any other files changed, add a text file
    # with the Skia revision number that was used to generate these baselines.
    # Then we can see which Skia revision number triggered the baseline changes.
    gm_output_dir = self.TargetPathJoin(
        self._gm_actual_dir, self._gm_image_subdir)
    if self._target_platform == TARGET_PLATFORM_WIN32:
      command = 'rmdir /s /q %s && mkdir %s && %s -w %s' % (
          gm_output_dir, gm_output_dir, path_to_gm, gm_output_dir)
    else:
      command = 'rm -rf %s && mkdir %s && %s -w %s' % (
          gm_output_dir, gm_output_dir, path_to_gm, gm_output_dir)
    self._skia_cmd_obj.AddRun(
        run_command=command, description='GenerateGMResults')
    if self._do_upload_results:
      self._skia_cmd_obj.AddMergeIntoSvn(
          source_dir_path=gm_output_dir,
          dest_svn_url='%s/%s' % (
              self._gm_actual_svn_baseurl, self._gm_image_subdir),
          svn_username_file=self._autogen_svn_username_file,
          svn_password_file=self._autogen_svn_password_file,
          commit_message=WithProperties(
              'UploadGMResults of r%%(%s:-)s on %s' % (
                  'revision', self._builder_name)),
          description='UploadGMResults')

    # Run "bench", piping the output somewhere so we can graph
    # results over time.
    #
    # TODO(epoger): Currently this is a hack--we just tell the slave to
    # pipe the output to a directory on local disk.
    # Eventually, we will want the master to capture the output and store it.
    #
    # Running bench can be quite slow, so run it fewer times if we aren't
    # recording the output.
    if self._perf_data_dir:
      count = BENCH_REPEAT_COUNT
    else:
      count = 2
    path_to_bench = self.TargetPathJoin('out', self._configuration, 'bench')
    base_command = '%s -repeat %d -timers wcg' % (
        path_to_bench, count)
    if self._perf_data_dir:
      # The WithProperties() stuff is very touchy and mysterious.
      # With trial and error, I was able to get it to assemble a filename
      # including the revision as follows...
      data_dir = self.TargetPathJoin(
          self._perf_data_dir, 'bench_r%%(%s:-)s_data' % 'revision')

      if self._target_platform == TARGET_PLATFORM_WIN32:
        command = WithProperties('%s > %s' % (base_command, data_dir))
      else:
        # TODO(epoger): added ugly chmod to make the data files world-readable
        command = WithProperties(
            '%s | tee %s && chmod a+r %s' % (base_command, data_dir, data_dir))
    else:
      command = base_command
    self._skia_cmd_obj.AddRun(
        run_command=command, description='RunBench', timeout=1200)

    # Generate and upload bench performance graphs (but only if we have been
    # recording bench output for this build type).
    if self._perf_data_dir:
      path_to_bench_graph_svg = self.TargetPathJoin(
          'bench', 'bench_graph_svg.py')
      graph_title = 'Bench_Performance_for_%s' % self._builder_name
      graph_filepath = self.TargetPathJoin(
          self._perf_graphs_dir, 'graph-%s.xhtml' % self._builder_name)
      gen_command = 'python %s -d %s -r -%d -f -%d -x %d -y %d -l %s > %s' % (
          path_to_bench_graph_svg, self._perf_data_dir,
          BENCH_GRAPH_NUM_REVISIONS, BENCH_GRAPH_NUM_REVISIONS,
          BENCH_GRAPH_X, BENCH_GRAPH_Y, graph_title, graph_filepath)
      self._skia_cmd_obj.AddRun(
          run_command=gen_command, description='GenerateBenchGraphs')
      if self._do_upload_results:
        self._skia_cmd_obj.AddUploadToBucket(
            source_filepath=graph_filepath, description='UploadBenchGraphs')

    return self._factory
